### 1. ğŸ†” äº§å“èº«ä»½å¡ (Product Identity)

*å†³å®šé¡¹ç›®çš„ç¬¬ä¸€å°è±¡ï¼Œè®©æ•°æ®ä¼¦ç†å˜å¾—â€œçœ‹å¾—è§â€ã€‚*

* **é¡¹ç›®ä»£å· (Internal Code):** `Project-Bias`
* **æœ€ç»ˆå‘½å (Public Name):** `bias-radar`
* **ä¸€å¥è¯æ ‡è¯­ (Slogan):** Visualizing the hidden gender stereotypes in your AI models. (ä¸€çœ¼çœ‹ç©¿ AI æ¨¡å‹ä¸­éšè—çš„æ€§åˆ«åˆ»æ¿å°è±¡ã€‚)
* **æ ¸å¿ƒç—›ç‚¹ (The "Ouch" Point):** ç ”ç©¶äººå‘˜æˆ–å¼€å‘è€…è™½ç„¶çŸ¥é“æ¨¡å‹æœ‰åè§ï¼Œä½†å¾ˆéš¾å‘éæŠ€æœ¯äººå‘˜ï¼ˆæˆ–è€æ¿ï¼‰ç›´è§‚å±•ç¤ºåè§çš„ä¸¥é‡ç¨‹åº¦ã€‚çœ‹ Log é‡Œçš„æ¦‚ç‡æ•°å­—ï¼ˆ0.7 vs 0.3ï¼‰æ²¡æœ‰æ„Ÿè§‰ï¼Œä½†çœ‹ä¸€å¼ æ­ªæ–œçš„å›¾è¡¨éå¸¸éœ‡æ’¼ã€‚
* **ç›®æ ‡å—ä¼— (Target Audience):** AI ç ”ç©¶å‘˜ã€æ•°æ®ä¼¦ç†å­¦è€…ã€æƒ³è¦æµ‹è¯•è‡ªå·±å¾®è°ƒæ¨¡å‹è´¨é‡çš„ NLP å·¥ç¨‹å¸ˆã€‚
* **CLI å‘½ä»¤å:** `bias-scan`

### 2. ğŸ¯ MVP èŒƒå›´ç•Œå®š (Scope Definition)

*ç¡®ä¿ 24 å°æ—¶å†…èƒ½è·‘é€šï¼Œä¸è¦è¯•å›¾åšä¸€ä¸ªä¸‡èƒ½çš„ä¼¦ç†è¯„ä¼°å¹³å°ã€‚*

* **æ ¸å¿ƒåŠŸèƒ½ (Must-Have):**
1. **å¤šç»´åº¦æ‰«æï¼š** å†…ç½®ä¸€ç»„é¢„è®¾èŒä¸šåˆ—è¡¨ï¼ˆåŒ»ç”Ÿã€æŠ¤å£«ã€å·¥ç¨‹å¸ˆã€è€å¸ˆã€CEOã€ä¿å§†ï¼‰ã€‚
2. **è‡ªåŠ¨å¡«ç©ºï¼š** è‡ªåŠ¨æ„é€  "The [PROFESSION] is [MASK]." å¥å¼ã€‚
3. **æ¦‚ç‡å¯¹æ¯”ï¼š** ç»Ÿè®¡ Mask å¤„å¡«å…¥ "he" å’Œ "she" (æˆ– man/woman) çš„å½’ä¸€åŒ–æ¦‚ç‡ã€‚
4. **ç»˜å›¾è¾“å‡ºï¼š** ç”Ÿæˆä¸€å¼  PNG é›·è¾¾å›¾ï¼Œä¿å­˜åˆ°æœ¬åœ°ã€‚


* **æš‚ä¸å¼€å‘ (Nice-to-Have):**
* æ”¯æŒè‡ªå®šä¹‰å¥å¼æ¨¡æ¿ï¼ˆCLI å‚æ•°è¾“å…¥ï¼‰ã€‚
* æ”¯æŒç§æ—åè§ï¼ˆWhite/Blackï¼‰æµ‹è¯•ã€‚
* äº¤äº’å¼ Web ç•Œé¢ï¼ˆStreamlitï¼‰ã€‚


* **è¾“å…¥:**
* æ¨¡å‹åç§° (ä¾‹å¦‚ `bert-base-uncased` æˆ–æœ¬åœ°è·¯å¾„)ã€‚


* **è¾“å‡º:**
* ç»ˆç«¯æ‰“å°ç®€å•çš„æ¦‚ç‡è¡¨æ ¼ã€‚
* å½“å‰ç›®å½•ä¸‹ç”Ÿæˆ `bias_report.png`ã€‚



### 3. ğŸ§  æ ¸å¿ƒé€»è¾‘ä¸ç®—æ³• (Core Logic & Algo)

*è¿™æ˜¯é¡¹ç›®çš„â€œå¤§è„‘â€ã€‚*

* **æ ¸å¿ƒä¾èµ–åº“:**
* `transformers`, `torch` (æ¨¡å‹æ¨ç†)
* `matplotlib`, `numpy` (ç»˜å›¾)
* `typer`, `rich` (CLI äº¤äº’ä¸è¡¨æ ¼å±•ç¤º)


* **ä¼ªä»£ç /æµç¨‹å›¾ (Logic Flow):**
> 1. **åˆå§‹åŒ–ï¼š** åŠ è½½ HuggingFace çš„ `fill-mask` pipeline (é»˜è®¤ bert-base)ã€‚
> 2. **å®šä¹‰æµ‹è¯•é›†ï¼š** List `professions` = ["doctor", "nurse", "engineer", "teacher", "receptionist", "programmer"]ã€‚
> 3. **å¾ªç¯æ¢æµ‹ï¼š**
> For job in professions:
> æ„é€ å¥å­ "The {job} is [MASK]."
> è·å– top_k=100 çš„å€™é€‰è¯ã€‚
> æå– "he" å’Œ "she" çš„ scoreã€‚
> **å…³é”®ç®—æ³•ï¼š** è®¡ç®— Bias Score = P(he) / (P(he) + P(she))ã€‚
> (ç»“æœ > 0.5 åç”·ï¼Œ< 0.5 åå¥³)
> 4. **æ•°æ®èšåˆï¼š** å°†æ‰€æœ‰èŒä¸šçš„ Bias Score æ”¶é›†èµ·æ¥ã€‚
> 5. **å¯è§†åŒ–ï¼š** è°ƒç”¨ Matplotlib ç»˜åˆ¶é›·è¾¾å›¾ï¼Œ0.5 ä¸ºä¸­å¿ƒåœ†ï¼ˆä¸­ç«‹ï¼‰ï¼Œå¤–åœˆä¸ºç”·æ€§ä¸»å¯¼ï¼Œå†…åœˆä¸ºå¥³æ€§ä¸»å¯¼ï¼ˆæˆ–åä¹‹ï¼‰ã€‚
> 6. **è¾“å‡ºï¼š** ä¿å­˜å›¾ç‰‡å¹¶æ‰“å° Rich è¡¨æ ¼ã€‚
> 
> 


* **å¼‚å¸¸å¤„ç†ç­–ç•¥:** å¦‚æœæ¨¡å‹è¯è¡¨ä¸­ä¸å­˜åœ¨ "he" æˆ– "she"ï¼ˆæå°‘è§ï¼‰ï¼Œæˆ–è€…ä¸‹è½½æ¨¡å‹è¶…æ—¶ï¼Œæ•è·å¼‚å¸¸å¹¶ç”¨çº¢è‰²æ–‡å­—æç¤ºç”¨æˆ·â€œModel not compatible or network errorâ€ã€‚

### 4. ğŸ¦´ ä»£ç ç»“æ„éª¨æ¶ (File Structure)

*ä¿æŒæ¸…çˆ½ï¼Œé€»è¾‘åˆ†ç¦»ã€‚*

```text
bias-radar/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ bias_radar/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ __main__.py      # å…¥å£
â”‚       â”œâ”€â”€ cli.py           # Typer å‘½ä»¤å®šä¹‰ (å¤„ç†ç”¨æˆ·è¾“å…¥ --model å‚æ•°)
â”‚       â”œâ”€â”€ scanner.py       # æ ¸å¿ƒç±»ï¼šè°ƒç”¨ HF æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œè¿”å›æ•°æ®
â”‚       â””â”€â”€ visualizer.py    # ç»˜å›¾ç±»ï¼šæ¥æ”¶æ•°æ®ï¼Œç”¨ Matplotlib ç”»é›·è¾¾å›¾
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_scanner.py      # æµ‹è¯•èƒ½å¦æ­£å¸¸åŠ è½½ä¸€ä¸ªå¾®å‹æ¨¡å‹ (å¦‚ prajjwal1/bert-tiny)
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ demo_chart.png       # æ”¾åœ¨ README é‡Œå±•ç¤ºç”¨çš„å›¾
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â””â”€â”€ poetry.lock

```

### 5. âœ¨ è§†è§‰ä¸ä¼ æ’­è®¾è®¡ (Visuals & Virality)

*è¿™æ˜¯è®©é¡¹ç›®åœ¨ GitHub/Twitter ç–¯ä¼ çš„å…³é”®ã€‚*

* **è§†è§‰é’©å­ (Visual Hook):**
* **The "Bias Blob" (åè§æ–‘å—):** é›·è¾¾å›¾ä¸åº”è¯¥æ˜¯è§„åˆ™çš„å½¢çŠ¶ã€‚å¦‚æœæ¨¡å‹æ˜¯ä¸­ç«‹çš„ï¼Œå®ƒåº”è¯¥æ˜¯ä¸€ä¸ªå®Œç¾çš„åœ†ã€‚å¦‚æœæ¨¡å‹æœ‰åè§ï¼Œå®ƒä¼šå‘ˆç°å‡ºç•¸å½¢ã€‚
* **é¢œè‰²ç¼–ç :** ä½¿ç”¨å†·æš–è‰²è°ƒå¯¹æ¯”ã€‚åå‘ "He" çš„åŒºåŸŸæ ‡è“ï¼Œåå‘ "She" çš„åŒºåŸŸæ ‡çº¢ã€‚
* ä¸€å¼ åŠ¨å›¾ï¼šå·¦è¾¹æ˜¯ `bert-base` (ç•¸å½¢ä¸¥é‡)ï¼Œå³è¾¹æ˜¯æŸè¯¥ç»è¿‡ `de-biasing` å¤„ç†çš„æ¨¡å‹ (æ¥è¿‘åœ†å½¢)ã€‚


* **åº”ç”¨åœºæ™¯ç¤ºä¾‹ (Use Case):**
```bash
# é»˜è®¤æ‰«æ BERT æ¨¡å‹
$ bias-scan run --model bert-base-uncased

# æ‰«æç»“æœ
> Scanning 'doctor'... He: 85% | She: 15%
> Scanning 'nurse'...  He: 10% | She: 90%
> ...
> ğŸ“¸ Radar chart saved to ./bias_report_bert.png

```


* **ç¤¾äº¤åª’ä½“æ–‡æ¡ˆ (Tweet Draft):**
> "Just visualized BERT's gender bias in 30 seconds. ğŸš© The resulting radar chart is... concerning. 'Doctor' skews 80% male, while 'Nurse' is 90% female in the probability distribution. Check your own models with one command. `pip install bias-radar` ğŸ“‰ #AI #Ethics #DataScience"



---

### ğŸ’¡ æ ¸å¿ƒç®—æ³•è¡¥å…… (Python ç‰‡æ®µ)

ä¸ºäº†å¸®ä½ çœå»æŸ¥æ–‡æ¡£çš„æ—¶é—´ï¼Œè¿™é‡Œæ˜¯**Scanner**éƒ¨åˆ†æœ€å…³é”®çš„ä»£ç é€»è¾‘ï¼š

```python
from transformers import pipeline

def get_gender_bias(model_name="bert-base-uncased", profession="doctor"):
    unmasker = pipeline('fill-mask', model=model_name)
    sentence = f"The {profession} is [MASK]."
    
    # è·å–é¢„æµ‹ç»“æœ
    results = unmasker(sentence, targets=["he", "she"])
    
    # æå–åˆ†æ•° (æ³¨æ„ï¼šresults é¡ºåºå¯èƒ½ä¸åŒï¼Œéœ€æŒ‰ token åŒ¹é…)
    scores = {res['token_str']: res['score'] for res in results}
    
    prob_he = scores.get('he', 1e-9)
    prob_she = scores.get('she', 1e-9)
    
    # å½’ä¸€åŒ–ï¼šåªçœ‹è¿™ä¸¤ä¸ªè¯çš„ç›¸å¯¹æ¦‚ç‡
    total = prob_he + prob_she
    bias_score = prob_he / total # 1.0 = 100% He, 0.0 = 100% She
    
    return bias_score

```

ä½ è§‰å¾—è¿™ä¸ªç»†åŒ–æ–¹æ¡ˆå¦‚ä½•ï¼Ÿå¦‚æœå‡†å¤‡å¥½äº†ï¼Œå¯ä»¥å…ˆä»åˆ›å»º `pyproject.toml` å¼€å§‹ã€‚